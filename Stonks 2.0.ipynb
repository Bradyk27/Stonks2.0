{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 754,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import pandas_datareader as pdr\n",
    "import datetime\n",
    "import yfinance as yf\n",
    "import numpy as np\n",
    "from numpy import loadtxt\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import *\n",
    "import matplotlib.pyplot as plt\n",
    "import xlrd\n",
    "from featexp import get_univariate_plots\n",
    "from joblib import dump, load\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from xgboost import plot_importance\n",
    "from matplotlib import pyplot\n",
    "from numpy import sort\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "import xgboost as xgb\n",
    "import copy\n",
    "from sklearn.model_selection import cross_validate\n",
    "\n",
    "%matplotlib inline\n",
    "from matplotlib.pylab import rcParams\n",
    "rcParams['figure.figsize'] = 12, 4\n",
    "\n",
    "\n",
    "pd.options.mode.chained_assignment = None\n",
    "np.set_printoptions(suppress=True)\n",
    "\n",
    "#FEATURES\n",
    "#Prediction? Number of days trending upwards? Percentage increase?\n",
    "#Sell after a 5% increase?\n",
    "#Dissect what all of this means.\n",
    "#I want to get a precision / recall curve\n",
    "#Set rounding threshold lower\n",
    "#Confidence variables?\n",
    "#Try other models?\n",
    "#Try other stocks besides stocks that tend to just go up?\n",
    "#Predict rise in values rather than just simple classification?\n",
    "#Set rise rate higher / faster?\n",
    "#Invest money based on confidence / probability?\n",
    "#We call more about precision & accuracy than recall\n",
    "#Remove unnecessary features, prevent overfitting?\n",
    "#Paper trade over previous data...see how we would have fared?\n",
    "#Automate all of this?\n",
    "#NaN values a problem?\n",
    "#Overfitting based on general bullish tech stocks?\n",
    "#Rise 5% within 10 days or AT 10 days?\n",
    "#get model size / kernel size\n",
    "\n",
    "\n",
    "#TODOS\n",
    "#check calculations. RSI in particular. 9 or 10 days?\n",
    "#Understand features, overfitting. early_stopping? logloss vs roc_auc? \n",
    "#Normalize MACD? Normalize all values to be below 1?\n",
    "#Try different model? cat one?\n",
    "#Change train, test, validate to 2 yrs, 1 yr, 1yr\n",
    "#AUC vs Precision as metric?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 755,
   "metadata": {},
   "outputs": [],
   "source": [
    "def RSI_calc(start, lookback, df, date_time=True): #Calculate RSI for a given day\n",
    "        if date_time:\n",
    "            start = start.strftime(\"%Y-%m-%d\")\n",
    "        if ((df.index[df[\"DATE\"]==start][0])-lookback) < 0:\n",
    "            return None\n",
    "        df = df[(df.index[df[\"DATE\"]==start][0])-lookback:df.index[df[\"DATE\"]==start][0]]\n",
    "        \n",
    "        df['GAIN_LOSS'] = df.apply(lambda row : (row[\"CLOSE\"]-row[\"OPEN\"]) / row[\"OPEN\"] * 100, axis=1)\n",
    "        avg_gain = df.loc[df['GAIN_LOSS'] >= 0][\"GAIN_LOSS\"].mean()\n",
    "        avg_loss = df.loc[df['GAIN_LOSS'] < 0][\"GAIN_LOSS\"].mean() * -1\n",
    "        RSI = 100 - (100 / (1 + (avg_gain/avg_loss)))\n",
    "        return RSI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 756,
   "metadata": {},
   "outputs": [],
   "source": [
    "def daily_return(start, lookback, df, date_time=True): #Calculate daily return\n",
    "        if date_time:\n",
    "            start = start.strftime(\"%Y-%m-%d\")\n",
    "        if ((df.index[df[\"DATE\"]==start][0])-lookback) < 0:\n",
    "            return None\n",
    "        df = df[(df.index[df[\"DATE\"]==start][0])-lookback:df.index[df[\"DATE\"]==start][0]+1] #Include day?\n",
    "        df['daily_change'] = df.apply(lambda row: ((row['CLOSE'] - row['OPEN']) / row['OPEN']) * 100, axis=1)\n",
    "        avg_daily_return = df['daily_change'].mean()\n",
    "        return avg_daily_return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 757,
   "metadata": {},
   "outputs": [],
   "source": [
    "def weekly_return(start, lookback, df, date_time=True): #Calculate weekly return\n",
    "        if date_time:\n",
    "            start = start.strftime(\"%Y-%m-%d\")\n",
    "        if ((df.index[df[\"DATE\"]==start][0])-lookback) < 0:\n",
    "            return None\n",
    "        df = df[(df.index[df[\"DATE\"]==start][0])-lookback:df.index[df[\"DATE\"]==start][0]+1] #Include day?\n",
    "        df = df.iloc[::5, :]\n",
    "        df = df.reset_index()\n",
    "        weekly_change_sum = 0\n",
    "        for i in range(1, len(df)): #Would really like to not be hacky about this...but oh well\n",
    "            weekly_change_sum += ((df.iloc[i]['CLOSE'] - df.iloc[i-1]['CLOSE']) / df.iloc[i-1]['OPEN']) * 100\n",
    "        weekly_change_avg = weekly_change_sum / len(df)-1\n",
    "        return weekly_change_avg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 758,
   "metadata": {},
   "outputs": [],
   "source": [
    "def monthly_return(start, lookback, df, date_time=True): #Calculate monthly return\n",
    "        if date_time:\n",
    "            start = start.strftime(\"%Y-%m-%d\")\n",
    "        if ((df.index[df[\"DATE\"]==start][0])-lookback) < 0:\n",
    "            return None\n",
    "        if(lookback < 30):\n",
    "            return None\n",
    "        df = df[(df.index[df[\"DATE\"]==start][0])-lookback:df.index[df[\"DATE\"]==start][0]+1] #Include day?\n",
    "        df = df.iloc[::30, :]\n",
    "        df = df.reset_index()\n",
    "        monthly_change_sum = 0\n",
    "        for i in range(1, len(df)): #Would really like to not be hacky about this...but oh well\n",
    "            monthly_change_sum += ((df.iloc[i]['CLOSE'] - df.iloc[i-1]['CLOSE']) / df.iloc[i-1]['OPEN']) * 100\n",
    "        monthly_change_avg = monthly_change_sum / len(df)-1\n",
    "        return monthly_change_avg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 759,
   "metadata": {},
   "outputs": [],
   "source": [
    "def EMA(start, lookback, df): #Calculate MACD w/ appropriate subcalculations\n",
    "        df = df[(df.index[df[\"DATE\"]==start][0])-lookback:df.index[df[\"DATE\"]==start][0]+1]\n",
    "        df = df.reset_index()\n",
    "        SMA = (df['CLOSE'][0:lookback-1].sum()) / lookback\n",
    "        k = 2 / (lookback + 1)\n",
    "        EMA = (df.loc[df['DATE']==start]['CLOSE'] * k) + (SMA * (1-k))\n",
    "        return EMA\n",
    "    \n",
    "def MACD(start, lookback1, lookback2, df, date_time=True):\n",
    "        if date_time:\n",
    "            start = start.strftime(\"%Y-%m-%d\")\n",
    "        if ((df.index[df[\"DATE\"]==start][0])-lookback2) < 0:\n",
    "            return None\n",
    "        EMA_short = EMA(start, lookback1, df)\n",
    "        EMA_long = EMA(start, lookback2, df)\n",
    "        return float(EMA_short) - float(EMA_long)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 760,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ratio_avg_to_close(start, lookback, df, date_time=True): #Calc ratios\n",
    "        if date_time:\n",
    "            start = start.strftime(\"%Y-%m-%d\")\n",
    "        if ((df.index[df[\"DATE\"]==start][0])-lookback) < 0:\n",
    "            return None\n",
    "        df = df[(df.index[df[\"DATE\"]==start][0])-lookback:df.index[df[\"DATE\"]==start][0]+1]\n",
    "        df = df.reset_index()\n",
    "        mean_close = df[0:lookback]['CLOSE'].sum() / lookback\n",
    "        ratio = mean_close / df.iloc[lookback]['CLOSE']\n",
    "        return ratio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 761,
   "metadata": {},
   "outputs": [],
   "source": [
    "def target(start, look_forward, df, target, date_time=True): #Calculate target @ # of days\n",
    "        if date_time:\n",
    "            start = start.strftime(\"%Y-%m-%d\")\n",
    "        if ((df.index[df[\"DATE\"]==start][0])+look_forward) > len(df):\n",
    "            return None\n",
    "        df = df[(df.index[df[\"DATE\"]==start][0]):df.index[df[\"DATE\"]==start][0]+look_forward] #+1? 9 or 10 days?\n",
    "        df = df.reset_index()\n",
    "        percent_increase = (df.iloc[look_forward-1]['CLOSE'] - df.iloc[0]['CLOSE']) / df.iloc[0]['CLOSE'] * 100\n",
    "        if percent_increase >= target:\n",
    "            return True\n",
    "        else:\n",
    "            return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 762,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def calcutron(stock_data, stock_symbols, csv_export, csv_name, percent_increase, days_increase): #All the calculations\n",
    "    df_list = []\n",
    "    for stock in stock_symbols:\n",
    "        df = stock_data.loc[stock_data[\"TICKER\"]==stock]\n",
    "        for num in [5,10,30,60]:\n",
    "            df['RSI ' + str(num)] = df.apply(lambda row: RSI_calc(row['DATE'], num, df, True), axis=1)\n",
    "            df[\"AVG DAILY RETURN \" + str(num)] = df.apply(lambda row: daily_return(row['DATE'], num, df, True), axis=1)\n",
    "            df[\"AVG WEEKLY RETURN \" + str(num)] = df.apply(lambda row: weekly_return(row['DATE'], num, df, True), axis=1)\n",
    "            df[\"AVG MONTHLY RETURN \" + str(num)] = df.apply(lambda row: monthly_return(row['DATE'], num, df, True), axis=1)\n",
    "            df[\"RATIO \" + str(num)] = df.apply(lambda row: ratio_avg_to_close(row['DATE'], num, df, True), axis=1)\n",
    "        df[\"MACD 10_30\"] = df.apply(lambda row: MACD(row['DATE'], 10, 30, df, True), axis=1)\n",
    "        df[\"MACD 5_10\"] = df.apply(lambda row: MACD(row['DATE'], 5, 10, df, True), axis=1)\n",
    "        df[\"MACD 2_10\"] = df.apply(lambda row: MACD(row['DATE'], 2, 10, df, True), axis=1)\n",
    "        df['MACD 10_30 DIFF'] = df['MACD 10_30'].diff()\n",
    "        df['MACD 5_10 DIFF'] = df['MACD 5_10'].diff()\n",
    "        df['MACD 2_10 DIFF'] = df['MACD 2_10'].diff()\n",
    "        df[\"TARGET\"] = df.apply(lambda row: target(row['DATE'], days_increase, df, percent_increase, True), axis=1)\n",
    "        df_list.append(df)\n",
    "    stock_data = pd.concat(df_list)\n",
    "    stock_data['TARGET'].value_counts(normalize=True) * 100\n",
    "    if csv_export:\n",
    "        stock_data.to_excel(csv_name)\n",
    "    return stock_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 763,
   "metadata": {},
   "outputs": [],
   "source": [
    "def just_stock_data_within(train_stocks, export_csv, csv_name, days, percent_increase, days_increase):\n",
    "    stock_data = pd.DataFrame(columns=[\"Ticker\",\"Date\",\"Open\",\"High\",\"Low\",\"Close\"])\n",
    "    for stock in train_stocks:\n",
    "        y_finance_data = yf.Ticker(stock).history(start=(datetime.date.today()-datetime.timedelta(days=days)).strftime(\"%Y-%m-%d\")).reset_index()\n",
    "        y_finance_data.insert(0,\"Ticker\", stock)\n",
    "        y_finance_data = y_finance_data[['Ticker', 'Date','Open','High','Low','Close']]\n",
    "        stock_data = pd.concat([stock_data, y_finance_data])\n",
    "    stock_data = stock_data.rename(columns={\"Ticker\":\"TICKER\", \"Date\":\"DATE\", \"Open\":\"OPEN\", \"High\":\"HIGH\", \"Low\":\"LOW\", \"Close\":\"CLOSE\"})\n",
    "    stock_data = calcutron_within(stock_data, train_stocks, export_csv, csv_name, percent_increase, days_increase)\n",
    "\n",
    "    stock_data = stock_data.drop(['AVG MONTHLY RETURN 5','AVG MONTHLY RETURN 10'], axis=1)\n",
    "    stock_data = stock_data.dropna()\n",
    "\n",
    "    input_patterns = stock_data[features][60:len(stock_data)-10]\n",
    "    input_label = stock_data['TARGET'][60:len(stock_data)-10].astype(int) #Why are these floats? It bothers me.\n",
    "    return stock_data, input_patterns, input_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 764,
   "metadata": {},
   "outputs": [],
   "source": [
    "def just_stock_data(train_stocks, export_csv, csv_name, days, percent_increase, days_increase):\n",
    "    stock_data = pd.DataFrame(columns=[\"Ticker\",\"Date\",\"Open\",\"High\",\"Low\",\"Close\"])\n",
    "    for stock in train_stocks:\n",
    "        y_finance_data = yf.Ticker(stock).history(start=(datetime.date.today()-datetime.timedelta(days=days)).strftime(\"%Y-%m-%d\")).reset_index()\n",
    "        y_finance_data.insert(0,\"Ticker\", stock)\n",
    "        y_finance_data = y_finance_data[['Ticker', 'Date','Open','High','Low','Close']]\n",
    "        stock_data = pd.concat([stock_data, y_finance_data])\n",
    "    stock_data = stock_data.rename(columns={\"Ticker\":\"TICKER\", \"Date\":\"DATE\", \"Open\":\"OPEN\", \"High\":\"HIGH\", \"Low\":\"LOW\", \"Close\":\"CLOSE\"})\n",
    "    stock_data = calcutron(stock_data, train_stocks, export_csv, csv_name, percent_increase, days_increase)\n",
    "\n",
    "    stock_data = stock_data.drop(['AVG MONTHLY RETURN 5','AVG MONTHLY RETURN 10'], axis=1)\n",
    "    stock_data = stock_data.dropna()\n",
    "\n",
    "    input_patterns = stock_data[features][60:len(stock_data)-10]\n",
    "    input_label = stock_data['TARGET'][60:len(stock_data)-10].astype(int) #Why are these floats? It bothers me.\n",
    "    return stock_data, input_patterns, input_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 765,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create base model, read from CSV if we have one, perfrom 100 metric trials\n",
    "def model_creation(train_stocks, test_size, read_csv, export_csv, csv_name, days, percent_increase, days_increase, features=None, prints=False):\n",
    "    if read_csv:\n",
    "        stock_data = pd.read_excel(csv_name, engine='openpyxl')\n",
    "    else:\n",
    "        stock_data = pd.DataFrame(columns=[\"Ticker\",\"Date\",\"Open\",\"High\",\"Low\",\"Close\"])\n",
    "        for stock in train_stocks:\n",
    "            y_finance_data = yf.Ticker(stock).history(start=(datetime.date.today()-datetime.timedelta(days=days)).strftime(\"%Y-%m-%d\")).reset_index()\n",
    "            y_finance_data.insert(0,\"Ticker\", stock)\n",
    "            y_finance_data = y_finance_data[['Ticker', 'Date','Open','High','Low','Close']]\n",
    "            stock_data = pd.concat([stock_data, y_finance_data])\n",
    "        stock_data = stock_data.rename(columns={\"Ticker\":\"TICKER\", \"Date\":\"DATE\", \"Open\":\"OPEN\", \"High\":\"HIGH\", \"Low\":\"LOW\", \"Close\":\"CLOSE\"})\n",
    "        stock_data = calcutron(stock_data, train_stocks, export_csv, csv_name, percent_increase, days_increase)\n",
    "\n",
    "    stock_data = stock_data.drop(['AVG MONTHLY RETURN 5','AVG MONTHLY RETURN 10'], axis=1)\n",
    "    stock_data = stock_data.dropna()\n",
    "    print(stock_data)\n",
    "    if features == None:\n",
    "        input_patterns = stock_data.loc[:,'RSI 5':'MACD 2_10 DIFF'][60:len(stock_data)-10]\n",
    "    else:\n",
    "        input_patterns = stock_data[features][60:len(stock_data)-10]\n",
    "    \n",
    "    input_label = stock_data['TARGET'][60:len(stock_data)-10].astype(int) #Why are these floats? It bothers me.\n",
    "    if prints:\n",
    "        print(input_patterns)\n",
    "        print(stock_data['TARGET'].value_counts(normalize=True) * 100)\n",
    "    \n",
    "    accuracy_trials = []\n",
    "    recall_trials = []\n",
    "    precision_trials = []\n",
    "    auc_trials = []\n",
    "\n",
    "    for i in range(100):\n",
    "        X_train, X_test, y_train, y_test = train_test_split(input_patterns, input_label, test_size = test_size)\n",
    "        model = XGBClassifier(eval_metric=\"auc\", use_label_encoder=False)\n",
    "        model.fit(X_train, y_train)\n",
    "        accuracy_trials.append(accuracy_score(y_test, model.predict(X_test)) * 100.0)\n",
    "        precision_trials.append(precision_score(y_test, model.predict(X_test)) * 100.0)\n",
    "        recall_trials.append(recall_score(y_test, model.predict(X_test)) * 100.0)\n",
    "        average_precision_trials.append(average_precision_score(y_test, model.predict(X_test)))\n",
    "        auc_trials.append(roc_auc_score(y_test, model.predict(X_test)))\n",
    "\n",
    "    mean_accuracy = sum(accuracy_trials) / len(accuracy_trials)\n",
    "    mean_precision = sum(precision_trials) / len(precision_trials)\n",
    "    mean_recall= sum(recall_trials) / len(recall_trials)\n",
    "    mean_auc = sum(auc_trials) / len(auc_trials)\n",
    "\n",
    "    if prints:\n",
    "        print(\"Validation Trial\")\n",
    "        print(\"Mean Accuracy: {}%\".format(mean_accuracy))\n",
    "        print(\"Mean Precision: {}%\".format(mean_precision))\n",
    "        print(\"Mean Recall: {}%\".format(mean_recall))\n",
    "        print(\"Mean AUC: {}%\".format(mean_auc))\n",
    "        print(model)\n",
    "    return model, stock_data, X_train, X_test, y_train, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 766,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Perform testing trials on given stock\n",
    "def trials(model, threshold, test_stocks, days, export_csv, csv_name, percent_increase, days_increase, features, prints=False):\n",
    "    #Add ability to read from CSV here?\n",
    "    for stock in test_stocks:\n",
    "        print(stock)\n",
    "        stock_data_testing = pd.DataFrame(columns=[\"Ticker\",\"Date\",\"Open\",\"High\",\"Low\",\"Close\"])\n",
    "        y_finance_data = yf.Ticker(stock).history(start=(datetime.date.today()-datetime.timedelta(days=days)).strftime(\"%Y-%m-%d\")).reset_index()\n",
    "        y_finance_data.insert(0,\"Ticker\", stock)\n",
    "        y_finance_data = y_finance_data[['Ticker', 'Date','Open','High','Low','Close']]\n",
    "\n",
    "        stock_data_testing = pd.concat([stock_data_testing, y_finance_data])\n",
    "        stock_data_testing = stock_data_testing.rename(columns={\"Ticker\":\"TICKER\", \"Date\":\"DATE\", \"Open\":\"OPEN\", \"High\":\"HIGH\", \"Low\":\"LOW\", \"Close\":\"CLOSE\"})\n",
    "        stock_data_testing = calcutron(stock_data_testing, [stock], False, None, percent_increase, days_increase)\n",
    "        stock_data_testing = stock_data_testing.drop(['AVG MONTHLY RETURN 5','AVG MONTHLY RETURN 10'], axis=1)\n",
    "        stock_data_testing = stock_data_testing.dropna()\n",
    "        if features == None:\n",
    "            input_patterns_testing = stock_data_testing.loc[:,'RSI 5':'MACD 2_10 DIFF'][60:len(stock_data)-10]\n",
    "        else:\n",
    "            input_patterns_testing = stock_data_testing[features][60:len(stock_data)-10]\n",
    "    \n",
    "        input_label_testing = stock_data_testing['TARGET'][60:len(stock_data)-10].astype(int)\n",
    "        print(input_patterns_testing)\n",
    "        #if prints:\n",
    "            #print(stock_data_testing)\n",
    "            #print(input_patterns_testing)\n",
    "            #print(input_label_testing)\n",
    "\n",
    "        accuracy_trials_testing = []\n",
    "        recall_trials_testing = []\n",
    "        precision_trials_testing = []\n",
    "        auc_trials_testing = []\n",
    "\n",
    "        y_prob = model.predict_proba(input_patterns_testing)\n",
    "        y_prob_round = []\n",
    "        for row in y_prob:\n",
    "            if row[1] > threshold:\n",
    "                y_prob_round.append(1)\n",
    "            else:\n",
    "                y_prob_round.append(0)\n",
    "        y_pred = model.predict(input_patterns_testing)\n",
    "        \n",
    "        accuracy_trials_testing.append(accuracy_score(input_label_testing, y_pred) * 100.0)\n",
    "        precision_trials_testing.append(precision_score(input_label_testing, y_pred) * 100.0)\n",
    "        recall_trials_testing.append(recall_score(input_label_testing, y_pred) * 100.0)\n",
    "        auc_trials_testing.append(roc_auc_score(input_label_testing, y_pred) * 100)\n",
    "        mean_accuracy_testing = sum(accuracy_trials_testing) / len(accuracy_trials_testing)\n",
    "        mean_precision_testing = sum(precision_trials_testing) / len(precision_trials_testing)\n",
    "        mean_recall_testing = sum(recall_trials_testing) / len(recall_trials_testing)\n",
    "        mean_auc_testing = sum(auc_trials_testing) / len(auc_trials_testing)\n",
    "\n",
    "        if prints:\n",
    "            print(stock)\n",
    "            print(\"Standard Threshold\")\n",
    "            print(\"Accuracy {}: {}%\".format(stock, mean_accuracy_testing))\n",
    "            print(\"Precision {}: {}%\".format(stock, mean_precision_testing))\n",
    "            print(\"Recall {}: {}%\".format(stock, mean_recall_testing))\n",
    "            print(\"AUC {}: {}%\".format(stock, mean_auc_testing))\n",
    "            print()\n",
    "            \n",
    "        accuracy_trials_testing = []\n",
    "        recall_trials_testing = []\n",
    "        precision_trials_testing = []\n",
    "        auc_trials_testing = []\n",
    "\n",
    "        accuracy_trials_testing.append(accuracy_score(input_label_testing, y_prob_round) * 100.0)\n",
    "        precision_trials_testing.append(precision_score(input_label_testing, y_prob_round) * 100.0)\n",
    "        recall_trials_testing.append(recall_score(input_label_testing, y_prob_round) * 100.0)\n",
    "        auc_trials_testing.append(roc_auc_score(input_label_testing, y_pred) * 100)\n",
    "        mean_accuracy_testing = sum(accuracy_trials_testing) / len(accuracy_trials_testing)\n",
    "        mean_precision_testing = sum(precision_trials_testing) / len(precision_trials_testing)\n",
    "        mean_recall_testing = sum(recall_trials_testing) / len(recall_trials_testing)\n",
    "        mean_auc_testing = sum(auc_trials_testing) / len(auc_trials_testing)\n",
    "\n",
    "        if prints:\n",
    "            print(\"Rounding Threshold: {}\".format(threshold))\n",
    "            print(\"Accuracy {}: {}%\".format(stock, mean_accuracy_testing))\n",
    "            print(\"Precision {}: {}%\".format(stock, mean_precision_testing))\n",
    "            print(\"Recall {}: {}%\".format(stock, mean_recall_testing))\n",
    "            print(\"AUC {}: {}%\".format(stock, mean_auc_testing))\n",
    "            \n",
    "    return stock_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 767,
   "metadata": {},
   "outputs": [],
   "source": [
    "def target_within(start, look_forward, df, target, date_time=True): #New target function for within # of days instead of @\n",
    "        if date_time:\n",
    "            start = start.strftime(\"%Y-%m-%d\")\n",
    "        if ((df.index[df[\"DATE\"]==start][0])+look_forward) > len(df):\n",
    "            return None\n",
    "        df = df[(df.index[df[\"DATE\"]==start][0]):df.index[df[\"DATE\"]==start][0]+look_forward+1] #+1? 9 or 10 days?\n",
    "        df = df.reset_index()\n",
    "        for i in range(1,len(df)):\n",
    "            percent_increase = (df.iloc[i]['CLOSE'] - df.iloc[0]['CLOSE']) / df.iloc[0]['CLOSE'] * 100\n",
    "            if percent_increase >= target:\n",
    "                return True\n",
    "        return False\n",
    "\n",
    "def calcutron_within(stock_data, stock_symbols, csv_export, csv_name, percent_increase, days_increase): #Ditto as above\n",
    "    df_list = []\n",
    "    for stock in stock_symbols:\n",
    "        df = stock_data.loc[stock_data[\"TICKER\"]==stock]\n",
    "        for num in [5,10,30,60]:\n",
    "            df['RSI ' + str(num)] = df.apply(lambda row: RSI_calc(row['DATE'], num, df, True), axis=1)\n",
    "            df[\"AVG DAILY RETURN \" + str(num)] = df.apply(lambda row: daily_return(row['DATE'], num, df, True), axis=1)\n",
    "            df[\"AVG WEEKLY RETURN \" + str(num)] = df.apply(lambda row: weekly_return(row['DATE'], num, df, True), axis=1)\n",
    "            df[\"AVG MONTHLY RETURN \" + str(num)] = df.apply(lambda row: monthly_return(row['DATE'], num, df, True), axis=1)\n",
    "            df[\"RATIO \" + str(num)] = df.apply(lambda row: ratio_avg_to_close(row['DATE'], num, df, True), axis=1)\n",
    "        df[\"MACD 10_30\"] = df.apply(lambda row: MACD(row['DATE'], 10, 30, df, True), axis=1)\n",
    "        df[\"MACD 5_10\"] = df.apply(lambda row: MACD(row['DATE'], 5, 10, df, True), axis=1)\n",
    "        df[\"MACD 2_10\"] = df.apply(lambda row: MACD(row['DATE'], 2, 10, df, True), axis=1)\n",
    "        df['MACD 10_30 DIFF'] = df['MACD 10_30'].diff()\n",
    "        df['MACD 5_10 DIFF'] = df['MACD 5_10'].diff()\n",
    "        df['MACD 2_10 DIFF'] = df['MACD 2_10'].diff()\n",
    "        df[\"TARGET\"] = df.apply(lambda row: target_within(row['DATE'], days_increase, df, percent_increase, True), axis=1)\n",
    "        df_list.append(df)\n",
    "    stock_data = pd.concat(df_list)\n",
    "    stock_data['TARGET'].value_counts(normalize=True) * 100\n",
    "    if csv_export:\n",
    "        stock_data.to_excel(csv_name)\n",
    "    return stock_data\n",
    "\n",
    "\n",
    "def model_creation_within(train_stocks, test_size, read_csv, export_csv, csv_name, days, percent_increase, days_increase, features=None, prints=False):\n",
    "    if read_csv:\n",
    "        stock_data = pd.read_excel(csv_name, engine='openpyxl')\n",
    "    else:\n",
    "        stock_data = pd.DataFrame(columns=[\"Ticker\",\"Date\",\"Open\",\"High\",\"Low\",\"Close\"])\n",
    "        for stock in train_stocks:\n",
    "            y_finance_data = yf.Ticker(stock).history(start=(datetime.date.today()-datetime.timedelta(days=days)).strftime(\"%Y-%m-%d\")).reset_index()\n",
    "            y_finance_data.insert(0,\"Ticker\", stock)\n",
    "            y_finance_data = y_finance_data[['Ticker', 'Date','Open','High','Low','Close']]\n",
    "            stock_data = pd.concat([stock_data, y_finance_data])\n",
    "        stock_data = stock_data.rename(columns={\"Ticker\":\"TICKER\", \"Date\":\"DATE\", \"Open\":\"OPEN\", \"High\":\"HIGH\", \"Low\":\"LOW\", \"Close\":\"CLOSE\"})\n",
    "        stock_data = calcutron_within(stock_data, train_stocks, export_csv, csv_name, percent_increase, days_increase)\n",
    "\n",
    "    stock_data = stock_data.drop(['AVG MONTHLY RETURN 5','AVG MONTHLY RETURN 10'], axis=1)\n",
    "    stock_data = stock_data.dropna()\n",
    "    print(stock_data)\n",
    "    if features == None:\n",
    "        input_patterns = stock_data.loc[:,'RSI 5':'MACD 2_10 DIFF'][60:len(stock_data)-10]\n",
    "    else:\n",
    "        input_patterns = stock_data[features][60:len(stock_data)-10]\n",
    "    \n",
    "    input_label = stock_data['TARGET'][60:len(stock_data)-10].astype(int) #Why are these floats? It bothers me.\n",
    "    if prints:\n",
    "        print(input_patterns)\n",
    "        print(stock_data['TARGET'].value_counts(normalize=True) * 100)\n",
    "    \n",
    "    accuracy_trials = []\n",
    "    recall_trials = []\n",
    "    precision_trials = []\n",
    "    auc_trials = []\n",
    "\n",
    "    for i in range(100):\n",
    "        X_train, X_test, y_train, y_test = train_test_split(input_patterns, input_label, test_size = test_size)\n",
    "        model = XGBClassifier(eval_metric=\"auc\", use_label_encoder=False)\n",
    "        model.fit(X_train, y_train)\n",
    "        accuracy_trials.append(accuracy_score(y_test, model.predict(X_test)) * 100.0)\n",
    "        precision_trials.append(precision_score(y_test, model.predict(X_test)) * 100.0)\n",
    "        recall_trials.append(recall_score(y_test, model.predict(X_test)) * 100.0)\n",
    "        #average_precision_trials.append(average_precision_score(y_test, model.predict(X_test)))\n",
    "        auc_trials.append(roc_auc_score(y_test, model.predict(X_test)) * 100)\n",
    "\n",
    "    mean_accuracy = sum(accuracy_trials) / len(accuracy_trials)\n",
    "    mean_precision = sum(precision_trials) / len(precision_trials)\n",
    "    mean_recall= sum(recall_trials) / len(recall_trials)\n",
    "    mean_auc = sum(auc_trials) / len(auc_trials)\n",
    "\n",
    "    if prints:\n",
    "        print(\"Validation Trial\")\n",
    "        print(\"Mean Accuracy: {}%\".format(mean_accuracy))\n",
    "        print(\"Mean Precision: {}%\".format(mean_precision))\n",
    "        print(\"Mean Recall: {}%\".format(mean_recall))\n",
    "        print(\"Mean AUC: {}%\".format(mean_auc))\n",
    "        print(model)\n",
    "    return model, stock_data, X_train, X_test, y_train, y_test\n",
    "\n",
    "def trials_within(model, threshold, test_stocks, days, export_csv, csv_name, percent_increase, days_increase, features, prints=False):\n",
    "    #Add ability to read from CSV here?\n",
    "    for stock in test_stocks:\n",
    "        print(stock)\n",
    "        stock_data_testing = pd.DataFrame(columns=[\"Ticker\",\"Date\",\"Open\",\"High\",\"Low\",\"Close\"])\n",
    "        y_finance_data = yf.Ticker(stock).history(start=(datetime.date.today()-datetime.timedelta(days=days)).strftime(\"%Y-%m-%d\")).reset_index()\n",
    "        y_finance_data.insert(0,\"Ticker\", stock)\n",
    "        y_finance_data = y_finance_data[['Ticker', 'Date','Open','High','Low','Close']]\n",
    "\n",
    "        stock_data_testing = pd.concat([stock_data_testing, y_finance_data])\n",
    "        stock_data_testing = stock_data_testing.rename(columns={\"Ticker\":\"TICKER\", \"Date\":\"DATE\", \"Open\":\"OPEN\", \"High\":\"HIGH\", \"Low\":\"LOW\", \"Close\":\"CLOSE\"})\n",
    "        stock_data_testing = calcutron_within(stock_data_testing, [stock], False, None, percent_increase, days_increase)\n",
    "        stock_data_testing = stock_data_testing.drop(['AVG MONTHLY RETURN 5','AVG MONTHLY RETURN 10'], axis=1)\n",
    "        stock_data_testing = stock_data_testing.dropna()\n",
    "        if features == None:\n",
    "            input_patterns_testing = stock_data_testing.loc[:,'RSI 5':'MACD 2_10 DIFF'][60:len(stock_data)-10]\n",
    "        else:\n",
    "            input_patterns_testing = stock_data_testing[features][60:len(stock_data)-10]\n",
    "    \n",
    "        input_label_testing = stock_data_testing['TARGET'][60:len(stock_data)-10].astype(int)\n",
    "        print(input_patterns_testing)\n",
    "        #if prints:\n",
    "            #print(stock_data_testing)\n",
    "            #print(input_patterns_testing)\n",
    "            #print(input_label_testing)\n",
    "\n",
    "        accuracy_trials_testing = []\n",
    "        recall_trials_testing = []\n",
    "        precision_trials_testing = []\n",
    "        auc_trials_testing = []\n",
    "\n",
    "        y_prob = model.predict_proba(input_patterns_testing)\n",
    "        y_prob_round = []\n",
    "        for row in y_prob:\n",
    "            if row[1] > threshold:\n",
    "                y_prob_round.append(1)\n",
    "            else:\n",
    "                y_prob_round.append(0)\n",
    "        y_pred = model.predict(input_patterns_testing)\n",
    "        \n",
    "        accuracy_trials_testing.append(accuracy_score(input_label_testing, y_pred) * 100.0)\n",
    "        precision_trials_testing.append(precision_score(input_label_testing, y_pred) * 100.0)\n",
    "        recall_trials_testing.append(recall_score(input_label_testing, y_pred) * 100.0)\n",
    "        auc_trials_testing.append(roc_auc_score(input_label_testing, y_pred) * 100)\n",
    "        mean_accuracy_testing = sum(accuracy_trials_testing) / len(accuracy_trials_testing)\n",
    "        mean_precision_testing = sum(precision_trials_testing) / len(precision_trials_testing)\n",
    "        mean_recall_testing = sum(recall_trials_testing) / len(recall_trials_testing)\n",
    "        mean_auc_testing = sum(auc_trials_testing) / len(auc_trials_testing)\n",
    "\n",
    "        if prints:\n",
    "            print(stock)\n",
    "            print(\"Standard Threshold\")\n",
    "            print(\"Accuracy {}: {}%\".format(stock, mean_accuracy_testing))\n",
    "            print(\"Precision {}: {}%\".format(stock, mean_precision_testing))\n",
    "            print(\"Recall {}: {}%\".format(stock, mean_recall_testing))\n",
    "            print(\"AUC {}: {}%\".format(stock, mean_auc_testing))\n",
    "            print()\n",
    "        \n",
    "        accuracy_trials_testing = []\n",
    "        recall_trials_testing = []\n",
    "        precision_trials_testing = []\n",
    "        auc_trials_testing = []\n",
    "\n",
    "        accuracy_trials_testing.append(accuracy_score(input_label_testing, y_prob_round) * 100.0)\n",
    "        precision_trials_testing.append(precision_score(input_label_testing, y_prob_round) * 100.0) #This is unnecessary lol\n",
    "        recall_trials_testing.append(recall_score(input_label_testing, y_prob_round) * 100.0)\n",
    "        auc_trials_testing.append(roc_auc_score(input_label_testing, y_pred) * 100)\n",
    "        mean_accuracy_testing = sum(accuracy_trials_testing) / len(accuracy_trials_testing)\n",
    "        mean_precision_testing = sum(precision_trials_testing) / len(precision_trials_testing)\n",
    "        mean_recall_testing = sum(recall_trials_testing) / len(recall_trials_testing)\n",
    "        mean_auc_testing = sum(auc_trials_testing) / len(auc_trials_testing)\n",
    "\n",
    "        if prints:\n",
    "            print(\"Rounding Threshold: {}\".format(threshold))\n",
    "            print(\"Accuracy {}: {}%\".format(stock, mean_accuracy_testing))\n",
    "            print(\"Precision {}: {}%\".format(stock, mean_precision_testing))\n",
    "            print(\"Recall {}: {}%\".format(stock, mean_recall_testing))\n",
    "            print(\"AUC {}: {}%\".format(stock, mean_auc_testing))\n",
    "            \n",
    "    return stock_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 768,
   "metadata": {},
   "outputs": [],
   "source": [
    "def relevant_features(model, X_train, y_train, X_test, y_test, threshold):\n",
    "    model.fit(X_train, y_train)\n",
    "    plot_importance(model)\n",
    "    pyplot.show()\n",
    "    \n",
    "    thresholds = sort(model.feature_importances_) #Sort through and thresholding out the unnecessary features from above model\n",
    "    for thresh in thresholds:\n",
    "        selection = SelectFromModel(model, threshold=thresh, prefit=True)\n",
    "        select_X_train = selection.transform(X_train)\n",
    "        selection_model = XGBClassifier(use_label_encoder=False, eval_metric=\"auc\")\n",
    "        selection_model.fit(select_X_train, y_train)\n",
    "        select_X_test = selection.transform(X_test)\n",
    "        y_pred = selection_model.predict(select_X_test)\n",
    "        auc = roc_auc_score(y_test, y_pred)\n",
    "        precision = precision_score(y_test, y_pred)\n",
    "        print(\"Thresh=%.3f, n=%d, AUC: %.2f%%\" % (thresh, select_X_train.shape[1], auc*100.0))\n",
    "        print(\"Thresh=%.3f, n=%d, Precision: %.2f%%\" % (thresh, select_X_train.shape[1], precision*100.0))\n",
    "    \n",
    "    print(\"-----------------ROUNDING THRESHOLD OF {}---------------------\".format(threshold))\n",
    "    \n",
    "    thresholds = sort(model.feature_importances_) #Sort through and thresholding out the unnecessary features from above model\n",
    "    for thresh in thresholds:\n",
    "        selection = SelectFromModel(model, threshold=thresh, prefit=True)\n",
    "        select_X_train = selection.transform(X_train)\n",
    "        selection_model = XGBClassifier(use_label_encoder=False, eval_metric=\"auc\")\n",
    "        selection_model.fit(select_X_train, y_train)\n",
    "        select_X_test = selection.transform(X_test)\n",
    "        y_pred = selection_model.predict_proba(select_X_test)\n",
    "        y_prob_round = []\n",
    "        for row in y_pred:\n",
    "            if row[1] > threshold:\n",
    "                y_prob_round.append(1)\n",
    "            else:\n",
    "                y_prob_round.append(0)\n",
    "        y_pred = y_prob_round                          \n",
    "        auc = roc_auc_score(y_test, y_pred)\n",
    "        precision = precision_score(y_test, y_pred)\n",
    "        print(\"Thresh=%.3f, n=%d, AUC: %.2f%%\" % (thresh, select_X_train.shape[1], auc*100.0))\n",
    "        print(\"Thresh=%.3f, n=%d, Precision: %.2f%%\" % (thresh, select_X_train.shape[1], precision*100.0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 769,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hyper_parameter(model, X_train, y_train):\n",
    "    #Hypertuning of parameters ala https://www.analyticsvidhya.com/blog/2016/03/complete-guide-parameter-tuning-xgboost-with-codes-python/\n",
    "    param_test1 = {\n",
    "    'max_depth':range(9,11,1), #Room for tuning here\n",
    "    'min_child_weight':range(1,3,1),\n",
    "    'gamma':[i/10. for i in range(0,5)]\n",
    "    }\n",
    "\n",
    "    gsearch1 = GridSearchCV(estimator = model, param_grid = param_test1, scoring='roc_auc',n_jobs=4,iid=False, cv=5)\n",
    "    gsearch1.fit(X_train,y_train)\n",
    "    print(\"TEST EVERYTHING\")\n",
    "    print(\"CV Results: \", gsearch1.cv_results_)\n",
    "    print(\"Best Params: \", gsearch1.best_params_)\n",
    "    print(\"Best Score: \", gsearch1.best_score_)\n",
    "    return gsearch1.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 770,
   "metadata": {},
   "outputs": [],
   "source": [
    "def n_estimator(model, X_train, y_train):\n",
    "    xgb_param = model.get_xgb_params()\n",
    "    xgtrain = xgb.DMatrix(X_train, label=y_train)\n",
    "    cvresult = xgb.cv(xgb_param, xgtrain, num_boost_round=model.get_params()['n_estimators'], nfold=5, metrics='auc', early_stopping_rounds=50)\n",
    "    print(cvresult)\n",
    "    print(\"Ideal n_estimators: \", cvresult.shape[0])\n",
    "    model.set_params(n_estimators=cvresult.shape[0])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#'Within' testing w/ random sampling\n",
    "\n",
    "#Getting our data, outputting to excel, getting X_train, X_test, y_train, y_test, etc.\n",
    "stock_symbols = [\"KR\", \"WMT\", \"KO\", \"NVDA\", \"F\", \"XOM\", \"AMD\"]\n",
    "stock_data, input_patterns, input_label = just_stock_data_within(stock_symbols, True, \"WITHIN_STOCK.xlsx\", 1800, 5, 10)\n",
    "threshold=.85 #Rounding threshold\n",
    "\n",
    "#If we have an excel file, use this:\n",
    "#stock_data = pd.read_excel(csv_name, engine='openpyxl')\n",
    "#stock_data = stock_data.drop(['AVG MONTHLY RETURN 5','AVG MONTHLY RETURN 10'], axis=1)\n",
    "#stock_data = stock_data.dropna()\n",
    "#input_patterns = stock_data[features][60:len(stock_data)-10]\n",
    "#input_label = stock_data['TARGET'][60:len(stock_data)-10].astype(int) #Why are these floats? It bothers me.\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(input_patterns, input_label, test_size = .33) #Currently random splitting, look into 2yr, 1yr, 1yr of SPY\n",
    "#####################\n",
    "\n",
    "#Baseline testing\n",
    "accuracy_trials = []\n",
    "recall_trials = []\n",
    "precision_trials = []\n",
    "auc_trials = []\n",
    "\n",
    "for i in range(100):\n",
    "    model = XGBClassifier(eval_metric=\"auc\", use_label_encoder=False)\n",
    "    model.fit(X_train, y_train)\n",
    "    \n",
    "    accuracy_trials.append(accuracy_score(y_test, model.predict(X_test)) * 100.0)\n",
    "    precision_trials.append(precision_score(y_test, model.predict(X_test)) * 100.0)\n",
    "    recall_trials.append(recall_score(y_test, model.predict(X_test)) * 100.0)\n",
    "    auc_trials.append(roc_auc_score(y_test, model.predict(X_test)) * 100)\n",
    "\n",
    "mean_accuracy = sum(accuracy_trials) / len(accuracy_trials)\n",
    "mean_precision = sum(precision_trials) / len(precision_trials)\n",
    "mean_recall= sum(recall_trials) / len(recall_trials)\n",
    "mean_auc = sum(auc_trials) / len(auc_trials)\n",
    "\n",
    "print(\"BASELINE TRIAL\")\n",
    "print(\"Mean Accuracy: {}%\".format(mean_accuracy))\n",
    "print(\"Mean Precision: {}%\".format(mean_precision))\n",
    "print(\"Mean Recall: {}%\".format(mean_recall))\n",
    "print(\"Mean AUC: {}%\".format(mean_auc))\n",
    "\n",
    "accuracy_trials = []\n",
    "recall_trials = []\n",
    "precision_trials = []\n",
    "auc_trials = []\n",
    "\n",
    "for i in range(100):\n",
    "    model = XGBClassifier(eval_metric=\"auc\", use_label_encoder=False)\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict_proba(X_test)\n",
    "    y_prob_round = []\n",
    "    for row in y_pred:\n",
    "        if row[1] > threshold:\n",
    "            y_prob_round.append(1)\n",
    "        else:\n",
    "            y_prob_round.append(0)\n",
    "    y_pred = y_prob_round    \n",
    "    accuracy_trials.append(accuracy_score(y_test, y_pred) * 100.0)\n",
    "    precision_trials.append(precision_score(y_test, y_pred) * 100.0)\n",
    "    recall_trials.append(recall_score(y_test, y_pred) * 100.0)\n",
    "    auc_trials.append(roc_auc_score(y_test, y_pred) * 100)\n",
    "\n",
    "mean_accuracy = sum(accuracy_trials) / len(accuracy_trials)\n",
    "mean_precision = sum(precision_trials) / len(precision_trials)\n",
    "mean_recall= sum(recall_trials) / len(recall_trials)\n",
    "mean_auc = sum(auc_trials) / len(auc_trials)\n",
    "\n",
    "print(\"BASELINE TRIAL w/ THRESHOLDING\")\n",
    "print(\"Mean Accuracy: {}%\".format(mean_accuracy))\n",
    "print(\"Mean Precision: {}%\".format(mean_precision))\n",
    "print(\"Mean Recall: {}%\".format(mean_recall))\n",
    "print(\"Mean AUC: {}%\".format(mean_auc))\n",
    "\n",
    "print(model)\n",
    "#####################\n",
    "\n",
    "#Univariate plots\n",
    "X_train_full = copy.deepcopy(X_train)\n",
    "X_test_full = copy.deepcopy(X_test)\n",
    "X_train_full['TARGET'] = y_train\n",
    "X_test_full['TARGET'] = y_test\n",
    "get_univariate_plots(data=X_train_full, target_col =\"TARGET\", data_test=X_test_full)\n",
    "##################\n",
    "\n",
    "#Creating new default model\n",
    "model = XGBClassifier(\n",
    "    learning_rate =0.1,\n",
    "    n_estimators=1000,\n",
    "    max_depth=5,\n",
    "    min_child_weight=1,\n",
    "    gamma=0,\n",
    "    subsample=0.8,\n",
    "    colsample_bytree=0.8,\n",
    "    objective= 'binary:logistic',\n",
    "    nthread=4,\n",
    "    scale_pos_weight=1,\n",
    "    seed=27,\n",
    "    eval_metric=\"auc\", \n",
    "    use_label_encoder=False)\n",
    "##################\n",
    "\n",
    "#Extract relevant features, obtain new data w/ selected features\n",
    "relevant_features(model, X_train, y_train, X_test, y_test, threshold)\n",
    "selection = SelectFromModel(model, threshold=.038, prefit=True) \n",
    "print(selection)\n",
    "select_X_train = selection.transform(X_train)\n",
    "select_X_test = selection.transform(X_test)\n",
    "##################\n",
    "\n",
    "#N_estimator -> hyper_parameterization -> N_estimator again\n",
    "model = n_estimator(model, select_X_train, y_train)\n",
    "best_params = hyper_parameter(model, select_X_train, y_train)\n",
    "model.set_params(gamma=best_params['gamma'], max_depth=best_params['max_depth'], min_child_weight=best_params['min_child_weight'])\n",
    "model = n_estimator(model, select_X_train, y_train)\n",
    "dump(model, 'trained_model_all_features.joblib')\n",
    "print(model)\n",
    "##################\n",
    "\n",
    "#Test model on selected test data\n",
    "y_pred = model.predict(select_X_test)\n",
    "auc = roc_auc_score(y_test, y_pred)\n",
    "precision = precision_score(y_test, y_pred)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"AUC: {}\".format(auc*100.0))\n",
    "print(\"Precision: {}\".format(precision*100.0))\n",
    "print(\"Accuracy: {}\".format(accuracy*100.0))\n",
    "\n",
    "print(\"ROUNDING THRESHOLD OF {}\".format(threshold))\n",
    "y_pred = model.predict_proba(select_X_test)\n",
    "y_prob_round = []\n",
    "for row in y_pred:\n",
    "    if row[1] > threshold:\n",
    "        y_prob_round.append(1)\n",
    "    else:\n",
    "        y_prob_round.append(0)\n",
    "y_pred = y_prob_round           \n",
    "auc = roc_auc_score(y_test, y_pred)\n",
    "precision = precision_score(y_test, y_pred)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"AUC: {}\".format(auc*100.0))\n",
    "print(\"Precision: {}\".format(precision*100.0))\n",
    "print(\"Accuracy: {}\".format(accuracy*100.0))\n",
    "##################\n",
    "\n",
    "#Test model on validation data\n",
    "#test_stocks = [\"AAPL\", \"X\", \"TGT\", \"INTC\", \"JNJ\"] \n",
    "#stock_data_test = trials_within(model, .85, test_stocks, 1800, False, None, 5, 10, features=None, prints=True)\n",
    "#dump(model, 'trained_model_all_features.joblib')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
